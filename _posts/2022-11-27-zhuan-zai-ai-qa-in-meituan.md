---
title: 转载：美团知识图谱问答技术实践与探索
author: zhangzangqian
date: 2022-11-27 16:00:00 +0800
categories: [技术]
tags: [智能问答, 知识图谱, NLP, 转载]
math: true
mermaid: true
---

> 因为最近在搞一个智能问答系统，目前在学习相关方面的知识，感觉这片文章不错，转载以作备忘。
{: .prompt-tip}

## 背景与挑战

问答系统（Question Answering System, QA）是人工智能和自然语言处理领域中一个倍受关注并具有广泛发展前景的方向，它是信息检索系统的一种高级形式，可以用准确、简洁的自然语言回答用户用自然语言提出的问题。这项研究兴起的主要原因是人们对快速、准确地获取信息的需求，因此被广泛应用于工业界的各种业务场景中。美团在平台服务的售前、售中、售后全链路的多个场景中，用户都有大量的问题需要咨询商家。因此我们基于问答系统，以自动智能回复或推荐回复的方式，来帮助商家提升回答用户问题的效率，更快地解决用户的问题。

针对不同问题，美团的智能问答系统包含多路解决方案：

1. PairQA：采用信息检索技术，从社区已有回答的问题中返回与当前问题最接近的问题答案。
2. DocQA：基于阅读理解技术，从商家非结构化信息、用户评论中抽取出答案片段。
3. KBQA（Knowledge-based Question Answering）：基于知识图谱问答技术，从商家、商品的结构化信息中对答案进行推理。

本文主要分享在KBQA技术落地中的实践与探索。

在用户的问题中，包括着大量关于商品、商家、景区、酒店等相关基础信息及政策等信息咨询，基于KBQA技术能有效地利用商品、商家详情页中的信息，来解决此类信息咨询问题。用户输入问题后，KBQA系统基于机器学习算法对用户查询的问题进行解析、理解，并对知识库中的结构化信息进行查询、推理，最终将查询到的精确答案返回给用户。相比于PairQA和DocQA，KBQA的答案来源大多是商家数据，可信度更高。同时，它可以进行多跳查询、约束过滤，更好地处理线上的复杂问题。

实际落地应用时，KBQA系统面临着多方面的挑战，例如：

繁多的业务场景：美团平台业务场景众多，包涵了酒店、旅游、美食以及十多类生活服务业务，而不同场景中的用户意图都存在着差别，比如“早餐大概多少钱”，对于美食类商家需要回答人均价格，而对于酒店类商家则需要回答酒店内餐厅的价格明细。
带约束问题：用户的问题中通常带有众多条件，例如“故宫学生有优惠吗”，需要我们对故宫所关联的优惠政策进行筛选，而不是把所有的优惠政策都回答给用户。
多跳问题：用户的问题涉及到知识图谱中多个节点组成的路径，例如“XX酒店的游泳池几点开”，需要我们在图谱中先后找到酒店、游泳池、营业时间。
下面将详细讲述我们是如何设计高准确、低延时的KBQA系统，处理场景、上下文语境等信息，准确理解用户、捕捉用户意图，从而应对上述的挑战。

## 解决方案

KBQA系统的输入为用户Query，输出为答案。总体架构如下图1所示。最上层为应用层，包括对话以及搜索等多个入口。在获取到用户Query后，KBQA线上服务通过Query理解和召回排序模块进行结果计算，最终返回答案文本。除了在线服务之外，知识图谱的构建、存储也十分重要。用户不仅会关心商户的基本信息，也会询问观点类、设施信息类问题，比如景点好不好玩、酒店停车是否方便等。针对上述无官方供给的问题，我们构建了一套信息与观点抽取的流程，可以从商家非结构化介绍以及UGC评论中抽取出有价值的信息，从而提升用户咨询的满意度，我们将在下文进行详细介绍。

![图1 KBQA系统架构图](https://tva1.sinaimg.cn/large/008i3skNly1gw13mdyvdjj31830u0te1.jpg)

对于KBQA模型，目前的主流解决方案有两种，如下图2所示：

![图2 KBQA解决方案分类](https://tva1.sinaimg.cn/large/008i3skNly1gw13q3xt8aj31eo0owdki.jpg)

- 基于语义解析（Semantic Parsing-based）：对问句进行深度句法解析，并将解析结果组合成可执行的逻辑表达式（如SparQL），直接从图数据库中查询答案。
- 基于信息抽取（Information Retrieval）：先解析出问句的主实体，再从KG中查询出主实体关联的多个三元组，组成子图路径（也称多跳子图），之后分别对问句和子图路径编码、排序，返回分数最高的路径作为答案。

基于语义解析的方法可解释性更强，但这种方法需要标注大量的自然语言逻辑表达式，而信息抽取式的方法更偏向端到端的方案，在复杂问题、少样本情况下表现更好，但若子图过大，会显著降低计算的速度。

因此，考虑到两者的优势，我们采用将两者结合的方案。如下图3所示，整体的流程分为四大步骤，以“故宫周末有学生票吗”为例：

![图3 美团KBQA解决方案](https://tva1.sinaimg.cn/large/008i3skNly1gw13r5dsw2j31g30u0430.jpg)

1. Query理解：输入原始Query，输出Query理解结果。其中会对对Query进行句法分析，识别出用户查询的主实体是“故宫” 、业务领域为“旅游”、问题类型为一跳（One-hop）。
2. 关系识别：输入Query、领域、句法解析结果、候选关系，输出每个候选的分数。在这个模块中，我们借助依存分析强化Query的问题主干，召回旅游领域的相关关系，进行匹配排序，识别出Query中的关系为“门票”。
3. 子图召回：输入前两个模块中解析的主实体和关系，输出图谱中的子图（多个三元组）。对于上述例子，会召回旅游业务数据下主实体为“故宫”、关系为“门票”的所有子图。
4. 答案排序：输入Query和子图候选，输出子图候选的分数，如果Top1满足一定阈值，则输出作为答案。基于句法分析结果，识别出约束条件为“学生票”，基于此条件最终对Query-Answer对进行排序，输出满足的答案。

下面将介绍我们对于重点模块的建设和探索。

### 1 Query理解

Query理解是KBQA的第一个核心模块，负责对句子的各个成分进行细粒度语义理解，其中两个最重要的模块是：

实体识别和实体链接，输出问句中有意义的业务相关实体和类型，如商家名称、项目、设施、人群、时间等。
依存分析：以分词和词性识别结果为输入，识别问句的主实体、被提问信息、约束等。
实体识别是句法分析的重要步骤，我们先基于序列标注模型识别实体，再链接到数据库中的节点。对于该模块我们主要做了以下优化：

为了提升OOV（Out-of-Vocabulary）词的识别能力，我们对实体识别的序列标注模型进行了知识注入，利用已知的先验知识辅助新知识的发现。
考虑到实体嵌套的问题，我们的实体识别模块会同时输出粗粒度和细粒度的结果，保证后续模块对于Query的充分理解。
在问答的长Query场景下，利用上下文信息进行实体的链接，得到节点id。
最终，该模块会输出句子中各个重要成分的类型，如下图4所示：

![图4 Query理解流程及结果](https://tva1.sinaimg.cn/large/008i3skNly1gw13rrrb1ij31fa0o2wjl.jpg)

依存分析是句法分析的一种，它的目的是识别句子中词与词的非对称支配关系，在输出的结果中用有向弧表示，该弧线由从属词（dep）指向支配词（head）。对于KBQA任务，我们定义了五种关系，如下图5所示：

![图5 依存类型定义](https://tva1.sinaimg.cn/large/008i3skNly1gw13s6lhprj31dm0gcdhx.jpg)

依存分析主要有两种方案：基于转移的（Transition-based）和基于图的（Graph-based）。基于转移的依存分析将依存句法树的构建建模为一系列操作，由模型预测每一步的动作（shift、left_arc、right_arc），不断将未处理的节点入栈并赋予关系，最终构成句法树。基于图的方法则致力于在图中找出一棵最大生成树，也就是句子整体依存关系的全局最优解。考虑到基于图的方法是对全局进行搜索，准确率更高，我们采用较为经典的“Deep Biaffine Attention for Neural Dependency Parsing”模型，它的结构如下图6所示：

![图6 依存分析模型结构](https://tva1.sinaimg.cn/large/008i3skNly1gw13ttijj7j31ku0lyae2.jpg)

该模型先通过BiLSTM对词与词性的拼接向量进行编码，之后采用对用两个MLP头分别编码出h(arc-head)和h(arc-dep)向量，去除冗余信息。最终将各个时刻的向量拼接起来得到H(arc-head)和H(arc-dep)，且在H(arc-dep)上拼接了一个单位向量，加入中间矩阵U(arc)进行仿射变换，得到dep与head的点积分数矩阵S(arc)，找到每个词依存的head。

有了依存分析的结果，我们可以更好地识别关系、复杂问题，具体的特征使用方法将在下文进行介绍。

### 2 关系识别

关系识别是KBQA中另一个核心模块，目的是识别出用户Query所问的关系（Predicate），从而与主实体（Subject）联合确定唯一子图，得到答案（Object）。

在实践中，考虑到图谱中边关系的数量会不断增加，我们将关系识别建模为文本匹配任务，输入用户Query、Query特征和候选关系，输出关系匹配的分数。为了解决开头提到的多领域问题，我们在输入的特征中加入了领域信息，从而在领域表示中存储一定的领域相关知识，让模型更好地判断。同时，为了提升复杂Query的理解，我们在输入中还融入了句法信息，让模型可以更好地理解带约束、多跳的问题。

![图7 关系识别模型结构](https://tva1.sinaimg.cn/large/008i3skNly1gw13ud5gs0j312z0c940k.jpg)

随着大规模预训练语言模型的出现，BERT等大模型在匹配任务上取得了SOTA的结果，通常业界通用的方法主要归类为以下两种：

1. 表示型：也称“双塔模型”，它的主要思想是将两段文本转换成一个语义向量，然后在向量空间计算两向量的相似度，更侧重对语义向量表示层的构建。

2. 交互型：该方法侧重于学习句子中短语之间的对齐，并学习比较他们之间的对齐关系，最终将对齐整合后的信息聚合到预测层。由于交互型模型可以利用到文本之前的对齐信息，因而精度更高、效果更好，所以在本项目中我们采用交互型模型来解决匹配问题。

为了充分利用BERT的语义建模能力，同时考虑实际业务的线上延时要求，我们在推理加速、数据增强、知识增强方面做了以下三点优化：

1. 层次剪枝：BERT每层都会学到不同的知识，靠近输入侧会学到较为通用的句法知识，而靠近输出则会学习更多任务相关的知识，因此我们参考DistillBERT，采取Skip等间隔式层次剪枝，只保留对任务效果最好的3层，比单纯保留前三层的剪枝在F1-score上提升了4%，同时，实验发现不同剪枝方法效果差距可达7%。

2. 领域任务数据预精调：剪枝后，由于训练数据有限，3层模型的效果有不小的下降。通过对业务的了解，我们发现美团的“问大家”模块数据与线上数据的一致性很高，并对数据进行清洗，将问题标题和相关问题作为正例，随机选取字面相似度0.5-0.8之间的句子作为负例，生成了大量弱监督文本对，预精调后3层模型在准确率上提升超过4%，甚至超过了12层模型的效果。

3. 知识增强：由于用户的表达方式多种多样，准确识别用户的意图，需要深入语意并结合语法信息。为了进一步提升效果，同时解决部分Case，我们在输入中加入了领域与句法信息，将显式的先验知识融入BERT，在注意力机制的作用下，同时结合句法依存树结构，准确建模词与词之间的依赖关系，我们在业务数据以及五个大型公开数据集上做验证，对比BERT Base模型在准确率上平均提升1.5%。

经过上述一系列迭代后，模型的速度、准确率都有了大幅的提升。
